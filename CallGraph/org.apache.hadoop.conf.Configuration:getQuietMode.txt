org.apache.hadoop.io.nativeio.NativeIO:getOwner
org.apache.hadoop.ha.ZKFailoverController$3:run
org.apache.hadoop.ha.ZKFailoverController:access$400
org.apache.hadoop.ha.HAAdmin:run
org.apache.hadoop.ha.HAAdmin:runCmd
org.apache.hadoop.ha.HAAdmin:failover
org.apache.hadoop.ha.ZKFailoverController:doGracefulFailover
org.apache.hadoop.ha.HAAdmin:gracefulFailoverThroughZKFCs
org.apache.hadoop.fs.shell.Delete$Rm:processPath
org.apache.hadoop.fs.shell.Delete$Rm:moveToTrash
org.apache.hadoop.fs.viewfs.ViewFileSystem$1:getTargetFileSystem
org.apache.hadoop.conf.ReconfigurationServlet:doGet
org.apache.hadoop.ha.ZKFailoverController$ElectorCallbacks:fenceOldActive
org.apache.hadoop.ha.ZKFailoverController:access$1100
org.apache.hadoop.ha.ZKFailoverController:fenceOldActive
org.apache.hadoop.ha.ZKFailoverController:doFence
org.apache.hadoop.ha.FailoverController:failover
org.apache.hadoop.ha.HealthMonitor$MonitorDaemon:run
org.apache.hadoop.ha.HealthMonitor:access$500
org.apache.hadoop.ha.HealthMonitor:loopUntilConnected
org.apache.hadoop.ha.HealthMonitor:tryConnect
org.apache.hadoop.ha.ZKFailoverController$2:run
org.apache.hadoop.ha.ZKFailoverController:access$300
org.apache.hadoop.ha.ZKFailoverController$ElectorCallbacks:becomeActive
org.apache.hadoop.ha.ZKFailoverController:access$900
org.apache.hadoop.ha.ZKFailoverController$ElectorCallbacks:becomeStandby
org.apache.hadoop.ha.ZKFailoverController:access$1000
org.apache.hadoop.ha.FailoverController:preFailoverChecks
org.apache.hadoop.ha.HAAdmin:transitionToActive
org.apache.hadoop.ha.HealthMonitor:createProxy
org.apache.hadoop.ha.ZKFailoverController:doCedeActive
org.apache.hadoop.ha.HAAdmin:getServiceState
org.apache.hadoop.ha.ZKFailoverController:becomeActive
org.apache.hadoop.ha.ZKFailoverController:becomeStandby
org.apache.hadoop.ha.HAAdmin:transitionToStandby
org.apache.hadoop.ha.FailoverController:tryGracefulFence
org.apache.hadoop.ha.HAAdmin:checkHealth
org.apache.hadoop.ipc.Server$Listener$Reader:run
org.apache.hadoop.ipc.Server$Listener$Reader:doRunLoop
org.apache.hadoop.ipc.Server$Listener:doRead
org.apache.hadoop.ipc.Server$Connection:saslReadAndProcess
org.apache.hadoop.ipc.Server$Connection:readAndProcess
org.apache.hadoop.ipc.Server$Connection:unwrapPacketAndProcessRpcs
org.apache.hadoop.ipc.Server$Connection:processOneRpc
org.apache.hadoop.ipc.Server$Connection:processRpcOutOfBandRequest
org.apache.hadoop.ipc.Server$Connection:processConnectionContext
org.apache.hadoop.ipc.Server$Connection:authorizeConnection
org.apache.hadoop.security.authorize.ProxyUsers:authorize
org.apache.hadoop.fs.FileContext:createSymlink
org.apache.hadoop.io.BloomMapFile$Writer:<init>
org.apache.hadoop.io.ArrayFile$Writer:<init>
org.apache.hadoop.io.SequenceFile$Sorter:sort
org.apache.hadoop.io.SequenceFile$Sorter:sortAndIterate
org.apache.hadoop.io.SequenceFile$Sorter:mergePass
org.apache.hadoop.io.SequenceFile$Sorter:merge
org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue:merge
org.apache.hadoop.io.SequenceFile$Sorter:sortPass
org.apache.hadoop.io.SequenceFile$Sorter$SortPass:run
org.apache.hadoop.io.MapFile$Writer:<init>
org.apache.hadoop.io.SequenceFile$Sorter:cloneFileAttributes
org.apache.hadoop.io.SequenceFile$Sorter$SortPass:flush
org.apache.hadoop.io.MapFile:fix
org.apache.hadoop.fs.FileUtil:createJarWithClassPath
org.apache.hadoop.io.SequenceFile:createWriter
org.apache.hadoop.fs.FileContext:getLocalFSFileContext
org.apache.hadoop.ha.ZKFCRpcServer:gracefulFailover
org.apache.hadoop.ha.ZKFailoverController:run
org.apache.hadoop.ha.ZKFCRpcServer:cedeActive
org.apache.hadoop.ipc.Client$Connection:access$1500
org.apache.hadoop.io.BloomMapFile$Reader:<init>
org.apache.hadoop.fs.FsShell:main
org.apache.hadoop.fs.s3.MigrationTool:main
org.apache.hadoop.util.ToolRunner:run
org.apache.hadoop.util.GenericOptionsParser:<init>
org.apache.hadoop.util.GenericOptionsParser:parseGeneralOptions
org.apache.hadoop.util.GenericOptionsParser:processGeneralOptions
org.apache.hadoop.io.file.tfile.TFile:main
org.apache.hadoop.io.SequenceFile$RecordCompressWriter:<init>
org.apache.hadoop.io.SequenceFile$BlockCompressWriter:<init>
org.apache.hadoop.fs.FsShell:run
org.apache.hadoop.fs.shell.Command:runAll
org.apache.hadoop.fs.shell.Command:run
org.apache.hadoop.fs.shell.Command:processRawArguments
org.apache.hadoop.fs.shell.Command:expandArguments
org.apache.hadoop.fs.shell.Command:expandArgument
org.apache.hadoop.fs.shell.CommandWithDestination:getRemoteDestination
org.apache.hadoop.fs.shell.Display$Text:getInputStream
org.apache.hadoop.io.ArrayFile$Reader:<init>
org.apache.hadoop.io.SetFile$Reader:<init>
org.apache.hadoop.io.MapFile$Reader:<init>
org.apache.hadoop.io.MapFile$Reader:open
org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue:next
org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue:adjustPriorityQueue
org.apache.hadoop.fs.shell.Display$TextRecordInputStream:<init>
org.apache.hadoop.io.MapFile$Reader:createDataFileReader
org.apache.hadoop.io.SequenceFile$Sorter$SegmentDescriptor:nextRawKey
org.apache.hadoop.io.BloomMapFile$Reader:initBloomFilter
org.apache.hadoop.security.Credentials:readTokenStorageFile
org.apache.hadoop.io.file.tfile.TFileDumper:dumpInfo
org.apache.hadoop.security.Credentials:writeTokenStorageFile
org.apache.hadoop.io.SequenceFile$Writer:<init>
org.apache.hadoop.fs.shell.PathData:expandAsGlob
org.apache.hadoop.util.GenericOptionsParser:validateFiles
org.apache.hadoop.util.GenericOptionsParser:getLibJars
org.apache.hadoop.io.SequenceFile$Reader:<init>
org.apache.hadoop.fs.FsShell:getCurrentTrashDir
org.apache.hadoop.fs.FsShell:getTrash
org.apache.hadoop.fs.shell.Delete$Expunge:processArguments
org.apache.hadoop.fs.ChecksumFileSystem:copyToLocalFile
org.apache.hadoop.fs.FilterFileSystem:copyToLocalFile
org.apache.hadoop.fs.FileSystem:moveToLocalFile
org.apache.hadoop.fs.LocalDirAllocator:getLocalPathToRead
org.apache.hadoop.fs.LocalDirAllocator:createTmpFileForWrite
org.apache.hadoop.fs.LocalDirAllocator:getLocalPathForWrite
org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext:createTmpFileForWrite
org.apache.hadoop.fs.LocalDirAllocator:getAllLocalPathsToRead
org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext:getLocalPathToRead
org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext:getLocalPathForWrite
org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext:getAllLocalPathsToRead
org.apache.hadoop.fs.shell.CommandWithDestination:recursePath
org.apache.hadoop.fs.shell.CommandWithDestination:processPathArgument
org.apache.hadoop.fs.shell.CommandWithDestination:processPath
org.apache.hadoop.fs.shell.CommandWithDestination:getTargetPath
org.apache.hadoop.fs.shell.Command:processArguments
org.apache.hadoop.fs.shell.Command:processArgument
org.apache.hadoop.fs.shell.Command:processPathArgument
org.apache.hadoop.fs.shell.Command:processPaths
org.apache.hadoop.fs.shell.Command:recursePath
org.apache.hadoop.fs.shell.CommandWithDestination:copyFileToTarget
org.apache.hadoop.fs.shell.CommandWithDestination:copyStreamToTarget
org.apache.hadoop.fs.shell.CopyCommands$AppendToFile:expandArgument
org.apache.hadoop.fs.shell.Tail:expandArgument
org.apache.hadoop.fs.shell.CommandWithDestination:getLocalDestination
org.apache.hadoop.fs.shell.PathData:getPathDataForChild
org.apache.hadoop.fs.shell.CopyCommands$Merge:processOptions
org.apache.hadoop.fs.shell.PathData:getDirectoryContents
org.apache.hadoop.fs.shell.PathData:suffix
org.apache.hadoop.fs.shell.CopyCommands$Put:expandArgument
org.apache.hadoop.fs.FilterFileSystem:completeLocalOutput
org.apache.hadoop.fs.FileSystem:completeLocalOutput
org.apache.hadoop.fs.FileSystem:moveFromLocalFile
org.apache.hadoop.fs.FilterFileSystem:copyFromLocalFile
org.apache.hadoop.fs.FileSystem:copyToLocalFile
org.apache.hadoop.conf.Configuration:getLocalPath
org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext:confChanged
org.apache.hadoop.fs.shell.PathData:<init>
org.apache.hadoop.io.SecureIOUtils:<clinit>
org.apache.hadoop.fs.FileSystem:copyFromLocalFile
org.apache.hadoop.fs.FileSystemLinkResolver:resolve
org.apache.hadoop.fs.FsUrlConnection:getInputStream
org.apache.hadoop.fs.HarFileSystem:initialize
org.apache.hadoop.fs.Path:getFileSystem
org.apache.hadoop.fs.viewfs.ChRootedFileSystem:<init>
org.apache.hadoop.fs.Trash:<init>
org.apache.hadoop.fs.FileSystem:getLocal
org.apache.hadoop.fs.FileSystem:getNamed
org.apache.hadoop.fs.FileSystem$1:run
org.apache.hadoop.fs.FileSystem:getFSofPath
org.apache.hadoop.fs.FsUrlConnection:connect
org.apache.hadoop.fs.FsShell:getFS
org.apache.hadoop.fs.FileSystem:newInstanceLocal
org.apache.hadoop.fs.FileSystem$2:run
org.apache.hadoop.security.UserGroupInformation:getUGIFromTicketCache
org.apache.hadoop.fs.FileSystem:get
org.apache.hadoop.fs.FileSystem:newInstance
org.apache.hadoop.fs.viewfs.ViewFs:<init>
org.apache.hadoop.fs.viewfs.ViewFileSystem:initialize
org.apache.hadoop.fs.viewfs.ViewFs$1:<init>
org.apache.hadoop.fs.viewfs.ViewFileSystem$1:<init>
org.apache.hadoop.ipc.Server$Connection:saslProcess
org.apache.hadoop.ipc.Server$Connection:processSaslMessage
org.apache.hadoop.ipc.Server$Connection:buildSaslNegotiateResponse
org.apache.hadoop.ipc.WritableRpcEngine:getServer
org.apache.hadoop.ipc.ProtobufRpcEngine:getServer
org.apache.hadoop.ipc.WritableRpcEngine$Server:<init>
org.apache.hadoop.ipc.ProtobufRpcEngine$Server:<init>
org.apache.hadoop.ipc.RPC$Server:<init>
org.apache.hadoop.ipc.Server:<init>
org.apache.hadoop.ipc.Server$Connection:createSaslServer
org.apache.hadoop.ipc.Server:buildNegotiateResponse
org.apache.hadoop.ipc.RPC:waitForProxy
org.apache.hadoop.ha.protocolPB.ZKFCProtocolClientSideTranslatorPB:<init>
org.apache.hadoop.ipc.RPC:getProxy
org.apache.hadoop.fs.FileSystem$Cache:getUnique
org.apache.hadoop.fs.FileSystem:addFileSystemForTesting
org.apache.hadoop.fs.FileSystem$Cache:get
org.apache.hadoop.security.UserGroupInformation:getBestUGI
org.apache.hadoop.fs.viewfs.ViewFileSystem:<init>
org.apache.hadoop.fs.viewfs.InodeTree:<init>
org.apache.hadoop.security.SaslRpcServer:<init>
org.apache.hadoop.tools.GetGroupsBase:run
org.apache.hadoop.tools.GetGroupsBase:getUgmProtocol
org.apache.hadoop.security.UserGroupInformation:loginUserFromKeytabAndReturnUGI
org.apache.hadoop.ipc.RPC:waitForProtocolProxy
org.apache.hadoop.ha.protocolPB.HAServiceProtocolClientSideTranslatorPB:<init>
org.apache.hadoop.ipc.RPC:getProtocolProxy
org.apache.hadoop.fs.FileContext:<init>
org.apache.hadoop.fs.FileSystem$Cache$Key:<init>
org.apache.hadoop.security.SecurityUtil:doAsCurrentUser
org.apache.hadoop.security.UserGroupInformation:main
org.apache.hadoop.security.SaslRpcServer:create
org.apache.hadoop.security.SecurityUtil:doAsLoginUser
org.apache.hadoop.ha.ZKFailoverController:gracefulFailoverToYou
org.apache.hadoop.security.SecurityUtil:doAsLoginUserOrFatal
org.apache.hadoop.ipc.Client$Connection$1:run
org.apache.hadoop.security.UserGroupInformation:isLoginKeytabBased
org.apache.hadoop.ha.ZKFailoverController:cedeActive
org.apache.hadoop.ipc.Client$Connection:shouldAuthenticateOverKrb
org.apache.hadoop.security.UserGroupInformation:getCurrentUser
org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule:commit
org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker:invoke
org.apache.hadoop.ipc.WritableRpcEngine$Invoker:invoke
org.apache.hadoop.ipc.Client:call
org.apache.hadoop.ipc.Client:getConnection
org.apache.hadoop.ipc.Client$Connection:access$2600
org.apache.hadoop.security.SecurityUtil:login
org.apache.hadoop.security.UserGroupInformation:checkTGTAndReloginFromKeytab
org.apache.hadoop.security.UserGroupInformation$1:run
org.apache.hadoop.http.HttpServer:<init>
org.apache.hadoop.http.HttpServer:addDefaultServlets
org.apache.hadoop.http.HttpServer:addServlet
org.apache.hadoop.ipc.Client$Connection:setupIOstreams
org.apache.hadoop.security.UserGroupInformation:loginUserFromKeytab
org.apache.hadoop.io.SecureIOUtils:openFSDataInputStream
org.apache.hadoop.io.SecureIOUtils:openForRead
org.apache.hadoop.security.UserGroupInformation:reloginFromKeytab
org.apache.hadoop.security.UserGroupInformation:reloginFromTicketCache
org.apache.hadoop.security.UserGroupInformation:spawnAutoRenewalThreadForUserCreds
org.apache.hadoop.ipc.Client$Connection:<init>
org.apache.hadoop.security.SecurityUtil:openSecureHttpConnection
org.apache.hadoop.io.SecureIOUtils:openForRandomRead
org.apache.hadoop.http.HttpServer:addInternalServlet
org.apache.hadoop.security.UserGroupInformation:access$100
org.apache.hadoop.security.UserGroupInformation:isSecurityEnabled
org.apache.hadoop.io.SecureIOUtils:forceSecureOpenFSDataInputStream
org.apache.hadoop.io.SecureIOUtils:forceSecureOpenForRandomRead
org.apache.hadoop.io.SecureIOUtils:forceSecureOpenForRead
org.apache.hadoop.ipc.Server:access$3500
org.apache.hadoop.ipc.Server:authorize
org.apache.hadoop.jmx.JMXJsonServlet:doGet
org.apache.hadoop.conf.ConfServlet:doGet
org.apache.hadoop.metrics.MetricsServlet:doGet
org.apache.hadoop.http.HttpServer$StackServlet:doGet
org.apache.hadoop.http.HttpServer:isInstrumentationAccessAllowed
org.apache.hadoop.log.LogLevel$Servlet:doGet
org.apache.hadoop.http.AdminAuthorizedServlet:doGet
org.apache.hadoop.http.HttpServer:hasAdministratorAccess
org.apache.hadoop.security.authorize.ServiceAuthorizationManager:authorize
org.apache.hadoop.http.HttpServer:userHasAdministratorAccess
org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:getLinkTarget
org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:getFileStatus
org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:listStatus
org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:getFileStatus
org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:listStatus
org.apache.hadoop.io.SecureIOUtils:checkStat
org.apache.hadoop.security.UserGroupInformation:print
org.apache.hadoop.security.authorize.AccessControlList:isUserAllowed
org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:getFileLinkStatus
org.apache.hadoop.security.UserGroupInformation:createProxyUserForTesting
org.apache.hadoop.security.UserGroupInformation:getLoginUser
org.apache.hadoop.security.UserGroupInformation:isAuthenticationMethodEnabled
org.apache.hadoop.security.UserGroupInformation:getGroupNames
org.apache.hadoop.security.UserGroupInformation:createUserForTesting
org.apache.hadoop.security.UserGroupInformation:setConfiguration
org.apache.hadoop.security.UserGroupInformation:ensureInitialized
org.apache.hadoop.ipc.Server:refreshServiceAcl
org.apache.hadoop.security.authorize.ServiceAuthorizationManager:refresh
org.apache.hadoop.security.authorize.AccessControlList$1:newInstance
org.apache.hadoop.security.UserGroupInformation:initialize
org.apache.hadoop.security.authorize.AccessControlList:<init>
org.apache.hadoop.tools.protocolPB.GetUserMappingsProtocolClientSideTranslatorPB:isMethodSupported
org.apache.hadoop.security.protocolPB.RefreshAuthorizationPolicyProtocolClientSideTranslatorPB:isMethodSupported
org.apache.hadoop.security.protocolPB.RefreshUserMappingsProtocolClientSideTranslatorPB:isMethodSupported
org.apache.hadoop.security.ssl.SSLFactory:<init>
org.apache.hadoop.conf.ReconfigurationServlet:doPost
org.apache.hadoop.io.nativeio.NativeIO:ensureInitialized
org.apache.hadoop.ha.HAServiceTarget:getZKFCProxy
org.apache.hadoop.conf.ReconfigurableBase:<init>
org.apache.hadoop.security.SecurityUtil:<clinit>
org.apache.hadoop.io.SetFile$Writer:<init>
org.apache.hadoop.fs.Trash:moveToAppropriateTrash
org.apache.hadoop.io.file.tfile.Compression$Algorithm:<clinit>
org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:<init>
org.apache.hadoop.conf.Configuration:main
org.apache.hadoop.conf.ReconfigurationServlet:printConf
org.apache.hadoop.ha.FailoverController:<init>
org.apache.hadoop.io.nativeio.NativeIO$POSIX:<clinit>
org.apache.hadoop.io.MapFile:main
org.apache.hadoop.ha.HAServiceTarget:getProxy
org.apache.hadoop.util.RunJar:main
org.apache.hadoop.http.HttpConfig:<clinit>
org.apache.hadoop.security.authorize.ProxyUsers:refreshSuperUserGroupsConfiguration
org.apache.hadoop.fs.FileSystem:isSymlinksEnabled
org.apache.hadoop.fs.FileContext:getFileContext
org.apache.hadoop.security.Groups:getUserToGroupsMappingService
org.apache.hadoop.util.NativeLibraryChecker:main
org.apache.hadoop.ipc.RpcClientUtil:isMethodSupported
org.apache.hadoop.security.HadoopKerberosName:main
org.apache.hadoop.io.compress.CompressionCodecFactory:main
org.apache.hadoop.fs.DU:main
org.apache.hadoop.metrics.ganglia.GangliaContext31:init
org.apache.hadoop.fs.FsUrlStreamHandlerFactory:<init>
org.apache.hadoop.security.ssl.SSLFactory:readSSLConfiguration
org.apache.hadoop.security.UserGroupInformation$TestingGroups:<init>
org.apache.hadoop.fs.FsUrlStreamHandler:<init>
org.apache.hadoop.conf.ReconfigurationServlet:applyChanges
org.apache.hadoop.conf.Configuration:<init>
